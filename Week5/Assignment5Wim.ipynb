{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leren: Programming assignment 5\n",
    "\n",
    "**Student 1:**  <span style=\"color:red\">Wim Berkelmans</span> (<span style=\"color:red\">10793674</span>)<br>\n",
    "**Student 2:** <span style=\"color:red\">Philip Bouman</span> (<span style=\"color:red\">10668667</span>)<br>\n",
    "\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.linalg as linalg\n",
    "import scipy.ndimage\n",
    "import operator\n",
    "import math\n",
    "import sklearn\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import neighbors\n",
    "\n",
    "# Load data from .csv \n",
    "def readData():\n",
    "    training_set = np.loadtxt('digits123-1.csv', delimiter=';');\n",
    "    test_set = np.loadtxt('digits123-2.csv', delimiter=';');\n",
    "    return training_set, test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Gaussian Naive Bayes\n",
    "####  a) Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   0.   1. ...,   0.   0.   1.]\n",
      " [  0.   0.   4. ...,   1.   0.   1.]\n",
      " [  0.   0.   5. ...,   0.   0.   1.]\n",
      " ..., \n",
      " [  0.   0.   3. ...,   2.   0.   3.]\n",
      " [  0.   1.   7. ...,   0.   0.   3.]\n",
      " [  0.   2.  10. ...,   0.   0.   3.]]\n",
      "[  0.00000000e+00   6.23333333e-01   7.65000000e+00   1.34733333e+01\n",
      "   1.13666667e+01   5.02000000e+00   5.33333333e-01   3.33333333e-03\n",
      "   1.33333333e-02   3.43000000e+00   1.05400000e+01   1.14133333e+01\n",
      "   1.21300000e+01   8.36000000e+00   1.11333333e+00   1.00000000e-02\n",
      "   1.00000000e-02   2.40333333e+00   5.88000000e+00   7.68333333e+00\n",
      "   1.22833333e+01   7.49666667e+00   5.96666667e-01   0.00000000e+00\n",
      "   3.33333333e-03   8.13333333e-01   3.54000000e+00   9.33333333e+00\n",
      "   1.29733333e+01   5.31333333e+00   2.36666667e-01   0.00000000e+00\n",
      "   0.00000000e+00   2.66666667e-01   2.62333333e+00   8.40666667e+00\n",
      "   1.18100000e+01   6.28333333e+00   8.93333333e-01   0.00000000e+00\n",
      "   0.00000000e+00   3.53333333e-01   3.67666667e+00   7.89000000e+00\n",
      "   8.75666667e+00   6.36000000e+00   2.56333333e+00   1.00000000e-02\n",
      "   0.00000000e+00   8.70000000e-01   7.86000000e+00   1.04200000e+01\n",
      "   1.10266667e+01   1.01400000e+01   5.37000000e+00   4.33333333e-01\n",
      "   0.00000000e+00   5.80000000e-01   8.04666667e+00   1.33933333e+01\n",
      "   1.35100000e+01   9.30333333e+00   4.16333333e+00   1.35000000e+00\n",
      "   2.00000000e+00]\n",
      "[  0.00000000e+00   1.34145556e+00   2.50675000e+01   1.49626222e+01\n",
      "   2.28788889e+01   2.86462667e+01   3.20222222e+00   3.32222222e-03\n",
      "   1.98222222e-02   1.75917667e+01   2.96817333e+01   1.72558222e+01\n",
      "   1.96864333e+01   3.80304000e+01   7.34715556e+00   1.65666667e-02\n",
      "   1.65666667e-02   1.44873222e+01   2.99456000e+01   4.25363889e+01\n",
      "   1.84430556e+01   3.26699889e+01   2.84065556e+00   0.00000000e+00\n",
      "   3.32222222e-03   6.07182222e+00   2.52017333e+01   3.75155556e+01\n",
      "   1.64726222e+01   2.60684889e+01   1.08732222e+00   0.00000000e+00\n",
      "   0.00000000e+00   1.32222222e+00   1.91347889e+01   4.00812889e+01\n",
      "   1.93405667e+01   3.75097222e+01   4.32195556e+00   0.00000000e+00\n",
      "   0.00000000e+00   1.56848889e+00   2.55921222e+01   4.84512333e+01\n",
      "   3.72841222e+01   3.44037333e+01   1.82126556e+01   9.90000000e-03\n",
      "   0.00000000e+00   4.00643333e+00   3.11337333e+01   3.45969333e+01\n",
      "   2.36126222e+01   3.24404000e+01   2.62931000e+01   1.47888889e+00\n",
      "   0.00000000e+00   1.75026667e+00   2.90644889e+01   1.64319556e+01\n",
      "   1.00165667e+01   2.92113222e+01   3.23566556e+01   1.24075000e+01\n",
      "   6.80000000e-01]\n"
     ]
    }
   ],
   "source": [
    "# Main method\n",
    "def naiveBayes():\n",
    "    training_set, test_set = readData()\n",
    "    Ytrain = training_set[:,-1] # Y target values, last column of X\n",
    "#     Xtrain = np.delete(training_set, -1, 1) # remove target values\n",
    "    Xtrain = training_set\n",
    "    print Xtrain\n",
    "    Means = np.mean(Xtrain, axis=0)\n",
    "    Vars = np.var(Xtrain, axis=0)\n",
    "    print Means\n",
    "    print Vars\n",
    "\n",
    "naiveBayes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compare classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def logRegTrain(TrainX, TrainY, reg, maxI):\n",
    "    logreg = linear_model.LogisticRegression(C=reg, solver='newton-cg', \n",
    "                                    max_iter=maxI, multi_class='multinomial')\n",
    "    logreg.fit(TrainX, TrainY)\n",
    "    return logreg\n",
    "\n",
    "def logRegTest(logreg,TestX,TestY):\n",
    "    return logreg.score(TestX,TestY)\n",
    "\n",
    "\n",
    "# def logReg(Train, TrainY, Test, TestY):\n",
    "#     logreg = linear_model.LogisticRegression(C=0.001, solver='newton-cg', \n",
    "#                                     max_iter=100, multi_class='multinomial')\n",
    "#     logreg.fit(Train, TrainY)\n",
    "\n",
    "#     return logreg.score(Test,TestY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 180\n",
      "[[  0.   0.   5. ...,   0.   0.   1.]\n",
      " [  0.   0.   0. ...,   0.   0.   1.]\n",
      " [  0.   0.  16. ...,  16.   9.   1.]\n",
      " ..., \n",
      " [  0.   4.  13. ...,   2.   0.   3.]\n",
      " [  0.   1.   9. ...,   0.   0.   3.]\n",
      " [  0.   2.  10. ...,   0.   0.   3.]]\n",
      "CV 60\n",
      "[[  0.   0.   1. ...,   0.   0.   1.]\n",
      " [  0.   1.  13. ...,   1.   0.   1.]\n",
      " [  0.   0.   1. ...,   0.   0.   1.]\n",
      " ..., \n",
      " [  0.   0.   7. ...,   0.   0.   3.]\n",
      " [  0.   0.   8. ...,   0.   0.   3.]\n",
      " [  0.   0.   7. ...,   0.   0.   3.]]\n",
      "Test 60\n",
      "[[  0.   0.   4. ...,   1.   0.   1.]\n",
      " [  0.   0.   2. ...,   0.   0.   1.]\n",
      " [  0.   0.  10. ...,  16.  10.   1.]\n",
      " ..., \n",
      " [  0.   0.   8. ...,   0.   0.   3.]\n",
      " [  0.   0.   5. ...,   0.   0.   3.]\n",
      " [  0.   0.  10. ...,   0.   0.   3.]]\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# load data from file\n",
    "def readDigits(file):\n",
    "    data = np.loadtxt(file, delimiter=';')  \n",
    "    return data\n",
    "\n",
    "def init():\n",
    "    Digits = readDigits('digits123-1.csv')\n",
    "    # divide input into training set (60%), crossvalidation set (20%) and test set (20%)\n",
    "    m = len(Digits)\n",
    "    CV = Digits[::5]\n",
    "    Test = Digits[1::5]\n",
    "    Train1 = Digits[2::5]\n",
    "    Train2 = Digits[3::5]\n",
    "    Train3 = Digits[4::5]\n",
    "    Train = np.concatenate((Train1,Train2,Train3))\n",
    "    return Train, CV, Test\n",
    "\n",
    "Train, CV, Test = init()\n",
    "print 'Train',len(Train)\n",
    "print Train\n",
    "print 'CV',len(CV)\n",
    "print CV\n",
    "print 'Test',len(Test)\n",
    "print Test\n",
    "\n",
    "TrainY = Train[:,-1] # Y target values, last column\n",
    "TrainX = np.delete(Train, -1, 1) # remove target values\n",
    "CVY = CV[:,-1] # Y target values, last column\n",
    "CVX = np.delete(CV, -1, 1) # remove target values\n",
    "TestY = Test[:,-1] # Y target values, last column\n",
    "TestX = np.delete(Test, -1, 1) # remove target values\n",
    "\n",
    "# train logistic regression\n",
    "logreg = logRegTrain(TrainX, TrainY, 0.001, 20)\n",
    "# validate the parameters\n",
    "print logRegTest(logreg, CVX, CVY)\n",
    "# train logistic regression\n",
    "logreg = logRegTrain(TrainX, TrainY, 0.01, 20)\n",
    "# validate the parameters\n",
    "print logRegTest(logreg, CVX, CVY)\n",
    "# train logistic regression\n",
    "logreg = logRegTrain(TrainX, TrainY, 0.1, 20)\n",
    "# validate the parameters\n",
    "print logRegTest(logreg, CVX, CVY)\n",
    "# train logistic regression\n",
    "logreg = logRegTrain(TrainX, TrainY, 0.001, 200)\n",
    "# validate the parameters\n",
    "print logRegTest(logreg, CVX, CVY)\n",
    "# test the model\n",
    "logreg = logRegTrain(TrainX, TrainY, 0.001, 200)\n",
    "print logRegTest(logreg, TestX, TestY)\n",
    "# print logReg(TrainX, TrainY, TestX, TestY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
