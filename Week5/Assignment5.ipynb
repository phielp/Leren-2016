{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Implementation ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  60.8333333333\n",
      "[(4.5076557255914265e-65, 156), (4.8806794970637234e-65, 149), (6.3970153534652496e-65, 207), (2.4932007457562496e-63, 152), (1.6574780653238209e-62, 157), (9.8485919284844255e-62, 222), (1.6381044703392142e-57, 105), (9.2914534931736198e-57, 132), (2.5853255454796082e-55, 126), (3.1439978732073109e-54, 101)]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.linalg as linalg\n",
    "import scipy.ndimage\n",
    "import scipy.stats as sp\n",
    "import math\n",
    "\n",
    "def readData():\n",
    "    training = np.loadtxt('digits123-1.csv', delimiter=';')\n",
    "    test = np.loadtxt('digits123-2.csv', delimiter=';')\n",
    "    return training, test\n",
    "\n",
    "# Calculate mean for all features in dataset\n",
    "# return list of all means\n",
    "def calcMean(X):\n",
    "    m = len(X)\n",
    "    n = len(X[0])\n",
    "    totalSum = []\n",
    "    for i in range(n):\n",
    "        sum = 0\n",
    "        for j in range(m):\n",
    "            sum += float(X[j][i])\n",
    "\n",
    "        totalSum.append(float(sum / len(X)))\n",
    "\n",
    "    return totalSum\n",
    "\n",
    "# Calculate variance for all feautures in dataset\n",
    "# based on list of means and dataset\n",
    "def calcVar(X, mean):\n",
    "    m = len(X)\n",
    "    n = len(X[0])\n",
    "    totalSum = np.ones((m,n))\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            totalSum[j][i] = float((X[j][i] - mean[i])**2)\n",
    "    \n",
    "    # calc mean of variance per feature\n",
    "    var = calcMean(totalSum)\n",
    "    \n",
    "    return var\n",
    "         \n",
    "# returns the size of each class based on target values\n",
    "def classSize(Y):\n",
    "    size = []\n",
    "    uniques = list(set(Y))\n",
    "    for i in range(len(uniques)):\n",
    "        counter = 0\n",
    "        for j in range(len(Y)):\n",
    "            if Y[j] == uniques[i]:\n",
    "                counter +=1    \n",
    "        size.append(counter)\n",
    "    return size\n",
    "\n",
    "# calculate normal distribution\n",
    "def gaussian(mean, var, v):\n",
    "    if var != 0:\n",
    "        gaus = 1.0 / math.sqrt(2 * math.pi * var) * math.exp(-(v - mean)**2/(2*var))\n",
    "    else:\n",
    "        if v == mean:\n",
    "            gaus = 1\n",
    "        else:\n",
    "            gaus = 0\n",
    "            \n",
    "    return gaus\n",
    "\n",
    "# split dataset for each class\n",
    "def splitClasses(X, Y):\n",
    "    size = classSize(Y)\n",
    "    classes = []\n",
    "    class1 = X[0: size[0]]\n",
    "    classes.append(class1)\n",
    "    base = size[0]\n",
    "    for i in range(len(size)-1):\n",
    "        classN = X[base:base + size[i+1]]\n",
    "        base = base + size[i+1]\n",
    "        classes.append(classN)  \n",
    "        \n",
    "    return classes\n",
    "    \n",
    "# retrieve mean for each class\n",
    "def classMean(classes):\n",
    "    means = []\n",
    "    for i in range(len(classes)):\n",
    "        mean = calcMean(classes[i])\n",
    "        means.append(mean)\n",
    "    return means\n",
    "\n",
    "# retrieve variance for each class\n",
    "def classVars(classes, means):\n",
    "    variances = []\n",
    "    for i in range(len(classes)):\n",
    "        var = calcVar(classes[0], means[0])\n",
    "        variances.append(var)\n",
    "    return variances\n",
    "\n",
    "# claculate probabilities for each class\n",
    "def calcPDF(means, variances, testSet):\n",
    "    m = len(testSet)\n",
    "    n = len(testSet[0])-1\n",
    "    probabilities = np.ones((m,len(means)))\n",
    "    for h in range(len(means)):\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                prob = gaussian(means[h][j], variances[h][j] ,testSet[i][j])\n",
    "                if prob != 0:\n",
    "                    probabilities[i][h] *= prob\n",
    "\n",
    "    return probabilities\n",
    "\n",
    "# give best predictions for test set\n",
    "def predict(probabilities, Y):\n",
    "    uniques = list(set(Y))\n",
    "    predictions = []\n",
    "    finalProbs = []\n",
    "    for i in range(len(probabilities)):\n",
    "        best = probabilities[i].argmax(axis=0)\n",
    "        predictions.append(uniques[best])\n",
    "        \n",
    "        probs = probabilities[i].max()\n",
    "        finalProbs.append(probs)\n",
    "        \n",
    "    return predictions, finalProbs\n",
    "    \n",
    "# calculate the percentage of correct predictions\n",
    "def getAccuracy(test_set, target):\n",
    "    correct = 0\n",
    "    miss = []\n",
    "    for i in range(len(test_set)):\n",
    "        if test_set[i][-1] == target[i]:\n",
    "            correct += 1\n",
    "        else:\n",
    "            miss.append(i)\n",
    "            \n",
    "    accuracy = (correct/float(len(test_set))) * 100.0\n",
    "    return accuracy, miss\n",
    "\n",
    "# give back the n misclassifications with highset probability\n",
    "def highestMiss(prob, miss, n):\n",
    "    misclassified = {}\n",
    "    for i in range(len(miss)):\n",
    "        misclassified[prob[miss[i]]] = miss[i]\n",
    "    keys = sorted(misclassified.items(), key=lambda x: x[0])\n",
    "    return keys[-n:]\n",
    "    \n",
    "# main function\n",
    "def naiveBayes():\n",
    "    # preprocess data\n",
    "    dataSets = readData()\n",
    "    X = dataSets[0]\n",
    "    Y = X[:,-1]\n",
    "    X = np.delete(X, -1, 1)\n",
    "    testSet = dataSets[1]\n",
    "    \n",
    "    # split classes and calculate mean and variance for each class\n",
    "    classes = splitClasses(X, Y)\n",
    "    means = classMean(classes)\n",
    "    variances = classVars(classes, means)\n",
    "\n",
    "    # calculate pdf, predictions and accuracy\n",
    "    probs = calcPDF(means, variances, testSet)\n",
    "    pred, finalProbs = predict(probs, Y)\n",
    "    acc, miss = getAccuracy(testSet, pred)\n",
    "    \n",
    "    # examples with highest misclassification\n",
    "    misclassified = highestMiss(finalProbs, miss, 10)\n",
    "    \n",
    "    print \"Accuracy: \", acc\n",
    "    print misclassified\n",
    "        \n",
    "naiveBayes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy:  60.83 % <br>\n",
    "Ten misclassifications with highest probability (for digits123-2.csv): <br>\n",
    "101, 126, 132, 105, 222, 157, 152, 207, 149, 156"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
