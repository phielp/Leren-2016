{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leren: Programming assignment 2\n",
    "\n",
    "**Student 1:**  <span style=\"color:red\">Wim Berkelmans</span> (<span style=\"color:red\">10793674</span>)<br>\n",
    "**Student 2:** <span style=\"color:red\">Philip Bouman</span> (<span style=\"color:red\">10668667</span>)<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Linear Regression\n",
    "1) Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.linalg as linalg\n",
    "import scipy.ndimage\n",
    "import math\n",
    "\n",
    "def loadData(feature):\n",
    "    # load input:\n",
    "    # features: Bedrooms, Bathrooms, Size\n",
    "    # target: Price\n",
    "    data = np.loadtxt('HousesRegr.csv', skiprows = 1, delimiter=';');\n",
    "    columns = ['MLS','Bedrooms','Bathrooms','Size','Price']\n",
    "    index = columns.index(feature)\n",
    "    return data[:,index]\n",
    "\n",
    "bedroom = loadData('Bedrooms')\n",
    "bathroom = loadData('Bathrooms')\n",
    "size = loadData('Size')\n",
    "price = loadData('Price')\n",
    "\n",
    "# create easy format and add x_0's\n",
    "def designMatrix(n):\n",
    "    data = np.loadtxt('HousesRegr.csv', skiprows = 1, delimiter=';');\n",
    "    m = len(data)\n",
    "    X = np.ones((m,n))\n",
    "    for i in range(m):\n",
    "        for j in range(1,n):\n",
    "            X[i, j] = data[i,j]\n",
    "\n",
    "    return X\n",
    "\n",
    "# vectorize predicted output\n",
    "def targetVec(y):\n",
    "    Y = y[:, np.newaxis] \n",
    "    return Y\n",
    "\n",
    "def normalize(X):\n",
    "    n = len(X[0])\n",
    "    for i in range(1,n):\n",
    "        max_value = np.amax(X[:,i])\n",
    "        min_value = np.amin(X[:,i])\n",
    "        mean_value = np.mean(X[:,i])\n",
    "        mean_norm = np.subtract(X[:,i], mean_value)\n",
    "        range_value = max_value - min_value\n",
    "        X[:,i] = np.divide(mean_norm, range_value)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Gradient function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.73333333333\n"
     ]
    }
   ],
   "source": [
    "def gradient(X, Y, Thetas, theta):\n",
    "    # calculate the gradient for 1 paramater: param\n",
    "    # m = number of training examples\n",
    "    m = len(X)\n",
    "    # n = number of thetas\n",
    "    n = len(Thetas)\n",
    "    # loop over training examples \n",
    "    sum = 0\n",
    "    for i in range(m):\n",
    "        h = 0\n",
    "        # loop over features\n",
    "        for j in range(n):\n",
    "            h += Thetas[j] * X[i][j]\n",
    "            \n",
    "        sum += (h - Y[i]) * X[i][theta]\n",
    "    \n",
    "    gradient = 1.0/m * sum\n",
    "    return gradient\n",
    "\n",
    "# X = designMatrix(4)\n",
    "# Y = targetVec(price)\n",
    "X = np.array([[1,2,3],[1,4,5],[1,4,3]])\n",
    "Y = np.array([6,6,10])\n",
    "\n",
    "\n",
    "Thetas = [0.2, 0.2, 0.2]\n",
    "\n",
    "grad = gradient(X, Y, Thetas, 0)\n",
    "print grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Parameter updating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Version 1\n",
    "def updateThetas(X, Y, Thetas, alpha):\n",
    "    # number of training examples\n",
    "    m = len(X)\n",
    "    # number of features\n",
    "    n = len(X[0])\n",
    "    \n",
    "    grad = np.zeros(n)\n",
    "    new_thetas = np.zeros(n)\n",
    "    \n",
    "    # calculate gradient for each theta\n",
    "    for i in range(n):\n",
    "        grad[i] = gradient(X, Y, Thetas, i)\n",
    "        \n",
    "    # loop over thetas\n",
    "    for i in range(n):\n",
    "        new_thetas[i] = Thetas[i] - alpha * grad[i]\n",
    "        \n",
    "    return new_thetas\n",
    "\n",
    "# Alternate version (update parameters and gradient)\n",
    "def updateThetasAlt(X, Y, Thetas, alpha):\n",
    "    m = len(X)\n",
    "    n = len(X[0])\n",
    "    \n",
    "    theta_temp = np.zeros((m,n))\n",
    "    new_thetas = np.zeros(n) \n",
    "    \n",
    "    # loop over training examples\n",
    "    for i in range(m):\n",
    "\n",
    "        # loop over thetas/features\n",
    "        # calculate and store intermediate values for thetas (all the calculations for one training example)\n",
    "        for j in range(n):\n",
    "            theta_temp[i][j] = (np.sum(Thetas[:n] * X[i,:n]) - Y[i]) * X[i][j]\n",
    "    \n",
    "    # sum over intermediate values and apply learning rate and normalization\n",
    "    for i in range(n):\n",
    "        new_thetas[i] = Thetas[i] - alpha * 1.0/m * np.sum(theta_temp[0:m,i])\n",
    "    \n",
    "    return new_thetas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcCost(Thetas, X, Y):\n",
    "    m = len(X)\n",
    "    n = len(Thetas)\n",
    "    cost_sum = 0\n",
    "    \n",
    "    for i in range(n):  \n",
    "        cost_sum += (np.sum(Thetas[:n] * X[i,:n]) - Y[i])**2\n",
    "            \n",
    "    cost = cost_sum / (2.0*m)    \n",
    "    return cost\n",
    "\n",
    "def calcCostVec(Thetas, X, Y):\n",
    "    m = len(Y)\n",
    "    errorSquared = (np.dot(X, Thetas) - Y)**2\n",
    "    \n",
    "    # sum over errorSquared by multiplying with a rowvector of ones\n",
    "    ones = np.ones(m)\n",
    "    cost = np.dot(ones.T, errorSquared)/(2.0*m)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Main, optimization learning rate and iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input test data from written assignment:\n",
      "Final values of parameters:  [ 0.30023111  0.54391111  0.54176   ]\n",
      "Final cost:  7.39688291787\n",
      "\n",
      "Input is HousesRegr.csv, alpha =  1  with  200 iterations.\n",
      "Final values of parameters:  [  383329.11011524  -269334.98576148   620216.44819484  1546227.67924897]\n",
      "Final cost:  [ 86901044.21568717]\n",
      "\n",
      "\n",
      "Input is HousesRegr.csv, Vectorized\n",
      "Final values of parameters:  [[  383329.11011524]\n",
      " [-1005440.72589458]\n",
      " [  459811.58275449]\n",
      " [ 2068136.71838695]]\n",
      "Final cost:  [  3.17053703e+10]\n"
     ]
    }
   ],
   "source": [
    "def multiple(X, Y, Thetas, alpha, n_iter):\n",
    "    while n_iter > 0:\n",
    "        Thetas = updateThetas(X, Y, Thetas, alpha)\n",
    "        n_iter -= 1\n",
    "    return Thetas\n",
    "\n",
    "# alternative version; faster\n",
    "def multipleAlt(X, Y, Thetas, alpha, n_iter):\n",
    "    while n_iter > 0:\n",
    "        Thetas = updateThetasAlt(X, Y, Thetas, alpha)\n",
    "        n_iter -= 1\n",
    "    return Thetas\n",
    "\n",
    "# vectorized version\n",
    "def regressionVec(X, Y):\n",
    "    \n",
    "    # apply normal equation\n",
    "    norm = np.dot(np.dot(linalg.inv(np.dot(X.T, X)), X.T), Y)\n",
    "    return norm\n",
    "\n",
    "# test set as input\n",
    "X = np.array([[1,2,3],[1,4,5],[1,4,3]])\n",
    "Y = np.array([6,6,10])\n",
    "Thetas = [0.2,0.2,0.2]\n",
    "# print X\n",
    "print \"Input test data from written assignment:\"\n",
    "\n",
    "final_thetas = multiple(X, Y, Thetas, 0.01, 2)\n",
    "print \"Final values of parameters: \", final_thetas\n",
    "print \"Final cost: \", calcCost(final_thetas, X, Y)\n",
    "# final_thetas = multipleVec(X, Y, Thetas, 0.01, 2)\n",
    "# print \"Final values of parameters, vector based: \", final_thetas\n",
    "print \n",
    "\n",
    "# input is HousesRegr.csv\n",
    "X = designMatrix(4)\n",
    "X = normalize(X)\n",
    "# print X\n",
    "Y = targetVec(price)\n",
    "# print Y\n",
    "Thetas = [100000,100000,100000,100000]\n",
    "\n",
    "# alpha = 0.00000001\n",
    "# iters = 200\n",
    "# print \"Input is HousesRegr.csv, alpha = \", alpha, \" with \", iters, \"iterations.\"\n",
    "# final_thetas = multiple(X, Y, Thetas, alpha, iters)\n",
    "# print \"Final values of parameters: \", final_thetas\n",
    "# print \"Final cost: \", calcCost(final_thetas, X, Y)\n",
    "\n",
    "# alpha = 0.01\n",
    "# iters = 200\n",
    "# print \"Input is HousesRegr.csv, alpha = \", alpha, \" with \", iters, \"iterations.\"\n",
    "# final_thetas = multiple(X, Y, Thetas, alpha, iters)\n",
    "# print \"Final values of parameters: \", final_thetas\n",
    "# print \"Final cost: \", calcCost(final_thetas, X, Y)\n",
    "\n",
    "# alpha = 0.01\n",
    "# iters = 2000\n",
    "# print \"Input is HousesRegr.csv, alpha = \", alpha, \" with \", iters, \"iterations.\"\n",
    "# final_thetas = multiple(X, Y, Thetas, alpha, iters)\n",
    "# print \"Final values of parameters: \", final_thetas\n",
    "# print \"Final cost: \", calcCost(final_thetas, X, Y)\n",
    "\n",
    "# alpha = 0.1\n",
    "# iters = 200\n",
    "# print \"Input is HousesRegr.csv, alpha = \", alpha, \" with \", iters, \"iterations.\"\n",
    "# final_thetas = multiple(X, Y, Thetas, alpha, iters)\n",
    "# print \"Final values of parameters: \", final_thetas\n",
    "# print \"Final cost: \", calcCost(final_thetas, X, Y)\n",
    "\n",
    "alpha = 1\n",
    "iters = 200\n",
    "print \"Input is HousesRegr.csv, alpha = \", alpha, \" with \", iters, \"iterations.\"\n",
    "final_thetas = multiple(X, Y, Thetas, alpha, iters)\n",
    "print \"Final values of parameters: \", final_thetas\n",
    "print \"Final cost: \", calcCost(final_thetas, X, Y)\n",
    "\n",
    "# alpha = 1\n",
    "# iters = 2000\n",
    "# print \"Input is HousesRegr.csv, alpha = \", alpha, \" with \", iters, \"iterations.\"\n",
    "# final_thetas = multiple(X, Y, Thetas, alpha, iters)\n",
    "# print \"Final values of parameters: \", final_thetas\n",
    "# print \"Final cost: \", calcCost(final_thetas, X, Y)\n",
    "\n",
    "# final_thetas = multipleVec(X, Y, Thetas, 0.01, 2)\n",
    "# print \"Final values of parameters, vector based: \", final_thetas\n",
    "# print \"Final cost, vector based: \", calcCostVec(final_thetas, X, Y)\n",
    "print \"\\n\"\n",
    "print \"Input is HousesRegr.csv, Vectorized\"\n",
    "final_thetas = regressionVec(X, Y)\n",
    "print \"Final values of parameters: \", final_thetas\n",
    "print \"Final cost: \", calcCostVec(final_thetas, X, Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:**\n",
    "\n",
    "The data from HousesRegr.csv are normalized.\n",
    "A bigger alpha improves the speed of convergence.\n",
    "\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression\n",
    "1) Extension to polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Optimization learning rate and iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input is HousesRegr.csv, alpha =  1  with  200 iterations.\n",
      "Final values of parameters:  [  383329.11011524  -286100.04351846  -265236.37361688   435657.51781904\n",
      "   211900.97704529  1088886.92732143   843084.29408607]\n",
      "Final cost:  [ 97929111.38177693]\n"
     ]
    }
   ],
   "source": [
    "X = designMatrix(4)\n",
    "X = np.repeat(X, 2, axis=1)\n",
    "X = np.delete(X, 1, 1)\n",
    "m = len(X)\n",
    "for i in range(m):\n",
    "    for j in range(3):\n",
    "        X[i,2*j + 2] = X[i,2*j + 2]**2\n",
    "        \n",
    "X = normalize(X)\n",
    "Y = targetVec(price)\n",
    "Thetas = [100000,100000,100000,100000,100000,100000,100000]\n",
    "\n",
    "alpha = 1\n",
    "iters = 200\n",
    "print \"Input is HousesRegr.csv, alpha = \", alpha, \" with \", iters, \"iterations.\"\n",
    "final_thetas = multiple(X, Y, Thetas, alpha, iters)\n",
    "print \"Final values of parameters: \", final_thetas\n",
    "print \"Final cost: \", calcCost(final_thetas, X, Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:**\n",
    "\n",
    "Adding squares of the input variables does not improve the cost.\n",
    "\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "1) Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create easy format and add x_0's\n",
    "def readData():\n",
    "    data = np.loadtxt('digits123.csv', delimiter=',');\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Gradient calculating and parameter updating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hypothesis function for logistic regression\n",
    "def hypothesis(thetas, x):\n",
    "    return 1.0 / (1.0 + np.exp(-np.dot(thetas, x)))\n",
    "\n",
    "\n",
    "# gradient and parameter updating\n",
    "def updateLog(X, Y, Thetas, alpha):\n",
    "    m = len(X)\n",
    "    n = len(Thetas)\n",
    "    \n",
    "    new_thetas = np.zeros(n) \n",
    "    theta_temp = np.zeros(m)\n",
    "    \n",
    "        \n",
    "    # loop over training examples\n",
    "    for i in range(m):\n",
    "\n",
    "        # loop over thetas/features\n",
    "        for j in range(n):\n",
    "            theta_temp[i] = 1.0 / (1.0 + np.exp(-np.sum(Thetas[:n] * X[i,:n]))) - Y[i]\n",
    "        \n",
    "    new_thetas = Thetas - alpha * 1/m * np.dot(X.T,theta_temp[:, np.newaxis])\n",
    "        \n",
    "    return new_thetas[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cost function for logistic regression\n",
    "def calcCostLog(thetas, X, Y):\n",
    "    m = len(X)\n",
    "    cost_sum = 0.0\n",
    "    \n",
    "    for i in range(m): \n",
    "        if Y[i] > 0:\n",
    "            cost_sum += math.log(hypothesis(thetas,X[i]))\n",
    "        else:\n",
    "            cost_sum += math.log(1 - hypothesis(thetas,X[i]))\n",
    "    return -(cost_sum/m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Pairwise comparison of classess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ik weet niet echt wat we hiermee moeten\n",
    "def splitClasses(thetas, y):\n",
    "    m = len(y)\n",
    "    n = len(thetas)\n",
    "    classes = list(set(y))\n",
    "    n_class = len(classes)\n",
    "    if n_class <= 2 and 0 in classes:\n",
    "        return thetas, y\n",
    "    else:\n",
    "        Y = np.zeros((m,n_class))\n",
    "        Thetas = np.zeros((n_class, n))\n",
    "        for i in range(n_class):\n",
    "            for j in range(m):\n",
    "                if y[j] == classes[i]:\n",
    "                    Y[j][i] = 1\n",
    "                else:\n",
    "                    Y[j][i] = 0\n",
    "            Thetas[i] = thetas\n",
    "        return Thetas[0], Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Optimization learning rate and iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def regressionLog(X, y, alpha, n_iter, thetas):\n",
    "    cost = []\n",
    "    # for number of iterations\n",
    "    while n_iter > 0:\n",
    "        # calculate cost\n",
    "        cost.append(calcCostLog(thetas, X, y))\n",
    "        # update values for theta\n",
    "        new_thetas = updateLog(X, y, thetas, alpha)\n",
    "        thetas = new_thetas        \n",
    "        n_iter -= 1\n",
    "    \n",
    "    # split classes\n",
    "    new_thetas, new_y = splitClasses(thetas, y)\n",
    "    \n",
    "    return new_thetas, cost\n",
    "    \n",
    "# input is digits123.csv\n",
    "X = readData()\n",
    "Y = X[:,-1] # Y target values, last column of X\n",
    "X = np.delete(X, -1, 1) # remove target values\n",
    "X = np.insert(X, 0, 1, axis=1) # insert first column with ones\n",
    "thetas = np.zeros(len(X[0]))\n",
    "\n",
    "new_thetas, cost = regressionLog(X, Y, 0.0001, 10, thetas)\n",
    "plt.plot(cost)\n",
    "plt.show\n",
    "\n",
    "# input is written assignment\n",
    "X = np.array([[1,5,3],[1,5,5],[1,3,3],[1,2,4]])\n",
    "Y = np.array([0,0,1,1])\n",
    "thetas = np.array([0.5,0.5,0.5])\n",
    "\n",
    "new_thetas, cost = regressionLog(X, Y, 0.01, 50, thetas)\n",
    "plt.plot(cost)\n",
    "plt.show\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:**\n",
    "\n",
    "[You discussion comes here]\n",
    "\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
